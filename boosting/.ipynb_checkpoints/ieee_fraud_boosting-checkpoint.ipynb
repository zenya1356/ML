{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056bf46a",
   "metadata": {},
   "source": [
    "\n",
    "# IEEE-CIS Fraud Detection: Boosting Pipeline (LightGBM, XGBoost, CatBoost)\n",
    "\n",
    "Этот ноутбук демонстрирует **полный ход работы** — от загрузки и анализа данных до обучения трёх моделей бустинга с корректной обработкой категориальных признаков и временного среза.\n",
    "\n",
    "**Модели:**\n",
    "- LightGBM (нативные категории)\n",
    "- XGBoost (OOF target encoding для категориальных)\n",
    "- CatBoost (нативные категории)\n",
    "\n",
    "> **Примечание:** ноутбук рассчитан на запуск локально или в окружении с достаточной памятью (8–16 GB+) и временем выполнения. Для экономии ресурсов предусмотрены опции downcast/подвыборки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aff089",
   "metadata": {},
   "source": [
    "## 1. Установка и импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc297b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip -q install kaggle lightgbm xgboost catboost category_encoders pandas matplotlib scikit-learn pyarrow fastparquet\n",
    "import os, gc, math, json, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e9334",
   "metadata": {},
   "source": [
    "## 2. Загрузка датасета (Kaggle) или использование локального пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Опционально: загрузка с Kaggle (нужно добавить kaggle.json в ~/.kaggle)\n",
    "# from pathlib import Path\n",
    "# kaggle_json = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "# if kaggle_json.exists():\n",
    "#     !kaggle competitions download -c ieee-fraud-detection -p ./data\n",
    "#     !unzip -n ./data/ieee-fraud-detection.zip -d ./data\n",
    "# else:\n",
    "#     print(\"⚠️ Kaggle API не настроен. Поместите файлы train_transaction.csv, train_identity.csv, \"\n",
    "#           \"test_transaction.csv, test_identity.csv и sample_submission.csv в папку ./data\")\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "train_tr_path = os.path.join(DATA_DIR, \"train_transaction.csv\")\n",
    "train_id_path = os.path.join(DATA_DIR, \"train_identity.csv\")\n",
    "test_tr_path  = os.path.join(DATA_DIR, \"test_transaction.csv\")\n",
    "test_id_path  = os.path.join(DATA_DIR, \"test_identity.csv\")\n",
    "sub_path      = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "for p in [train_tr_path, train_id_path, test_tr_path, test_id_path, sub_path]:\n",
    "    print((\"✓\" if os.path.exists(p) else \"✗\"), p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e27566",
   "metadata": {},
   "source": [
    "## 3. Функции для экономии памяти и чтения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b37f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type.kind in ['i','u','f']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if col_type.kind in ['i','u']:\n",
    "                if c_min >= 0:\n",
    "                    if c_max < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_max < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_max < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if np.iinfo(np.int8).min < c_min < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif np.iinfo(np.int16).min < c_min < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif np.iinfo(np.int32).min < c_min < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'object':\n",
    "            # не переводим автоматически в category, чтобы иметь контроль\n",
    "            pass\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Mem. {start_mem:.2f} MB → {end_mem:.2f} MB\")\n",
    "    return df\n",
    "\n",
    "def read_csv_safely(path):\n",
    "    # Вариант с dtype=None, чтобы дать Pandas самому определить, затем downcast\n",
    "    df = pd.read_csv(path)\n",
    "    return reduce_mem_usage(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1bd08",
   "metadata": {},
   "source": [
    "## 4. Загрузка и объединение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_tr = read_csv_safely(train_tr_path)\n",
    "train_id = read_csv_safely(train_id_path)\n",
    "test_tr  = read_csv_safely(test_tr_path)\n",
    "test_id  = read_csv_safely(test_id_path)\n",
    "\n",
    "train = train_tr.merge(train_id, how='left', on='TransactionID')\n",
    "test  = test_tr.merge(test_id,  how='left', on='TransactionID')\n",
    "\n",
    "print(\"train:\", train.shape, \"test:\", test.shape)\n",
    "train.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00299b2",
   "metadata": {},
   "source": [
    "## 5. Быстрый EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_col = 'isFraud'\n",
    "print(\"Target mean:\", train[target_col].mean())\n",
    "print(\"Missing ratio (train top 10):\")\n",
    "miss = train.isna().mean().sort_values(ascending=False).head(10)\n",
    "display(miss.to_frame('missing_ratio').T)\n",
    "\n",
    "print(\"numeric cols:\", train.select_dtypes(include=[np.number]).shape[1],\n",
    "      \"object cols:\", train.select_dtypes(include=['object']).shape[1])\n",
    "\n",
    "# Столбцы категорий-«паспорта» (примерная эвристика)\n",
    "candidate_cats = [c for c in train.columns if train[c].dtype == 'object']\n",
    "print(\"candidate categorical:\", len(candidate_cats))\n",
    "candidate_cats[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df8d5c9",
   "metadata": {},
   "source": [
    "## 6. Базовый Feature Engineering (временные фичи, логи, частоты)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TransactionDT — секунды с начала «нулевого» времени. Сделаем фичи:\n",
    "def add_time_features(df):\n",
    "    if 'TransactionDT' in df.columns:\n",
    "        df['DT'] = df['TransactionDT']\n",
    "        df['DT_day'] = (df['DT'] // (24*60*60)).astype('int32')\n",
    "        df['DT_hour'] = ((df['DT'] // (60*60)) % 24).astype('int16')\n",
    "        df['DT_dayofweek'] = (df['DT_day'] % 7).astype('int8')\n",
    "    return df\n",
    "\n",
    "def add_amount_features(df):\n",
    "    if 'TransactionAmt' in df.columns:\n",
    "        df['TransactionAmt_log1p'] = np.log1p(df['TransactionAmt'].astype(float))\n",
    "    return df\n",
    "\n",
    "def freq_encode(train, test, cols):\n",
    "    for c in cols:\n",
    "        fq = train[c].value_counts(dropna=False)\n",
    "        train[c + '_fq'] = train[c].map(fq)\n",
    "        test[c + '_fq']  = test[c].map(fq)\n",
    "    return train, test\n",
    "\n",
    "train = add_time_features(train)\n",
    "test  = add_time_features(test)\n",
    "train = add_amount_features(train)\n",
    "test  = add_amount_features(test)\n",
    "\n",
    "# Примеры частотных энкодингов для card1/addr1/emaildomain при наличии\n",
    "freq_cols = [c for c in ['card1','addr1','P_emaildomain','R_emaildomain'] if c in train.columns]\n",
    "train, test = freq_encode(train, test, freq_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be1330",
   "metadata": {},
   "source": [
    "## 7. Выбор признаков и временной сплит train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drop_cols = [target_col, 'TransactionID']\n",
    "\n",
    "features = [c for c in train.columns if c not in drop_cols]\n",
    "\n",
    "# Временной сплит по TransactionDT: последний хвост как валидация\n",
    "assert 'TransactionDT' in train.columns\n",
    "cutoff = np.quantile(train['TransactionDT'], 0.85)  # 85% train, 15% valid\n",
    "trn_idx = train['TransactionDT'] < cutoff\n",
    "val_idx = ~trn_idx\n",
    "\n",
    "X_tr = train.loc[trn_idx, features].reset_index(drop=True)\n",
    "y_tr = train.loc[trn_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "X_va = train.loc[val_idx, features].reset_index(drop=True)\n",
    "y_va = train.loc[val_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "\n",
    "X_te = test[features].reset_index(drop=True)\n",
    "\n",
    "print(X_tr.shape, X_va.shape, X_te.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e58cbd",
   "metadata": {},
   "source": [
    "## 8. Определение категориальных столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ca5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Эвристика: object → категориальные\n",
    "cat_cols = [c for c in features if train[c].dtype == 'object']\n",
    "num_cols = [c for c in features if c not in cat_cols]\n",
    "\n",
    "print(\"num_cols:\", len(num_cols), \"cat_cols:\", len(cat_cols))\n",
    "cat_cols[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453c583",
   "metadata": {},
   "source": [
    "## 9. LightGBM (нативные категории)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f466ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Приводим object к category\n",
    "def cast_category(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "X_tr_lgb = X_tr.copy()\n",
    "X_va_lgb = X_va.copy()\n",
    "X_te_lgb = X_te.copy()\n",
    "\n",
    "X_tr_lgb = cast_category(X_tr_lgb, cat_cols)\n",
    "X_va_lgb = cast_category(X_va_lgb, cat_cols)\n",
    "X_te_lgb = cast_category(X_te_lgb, cat_cols)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr_lgb, label=y_tr, categorical_feature=cat_cols, free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(X_va_lgb, label=y_va, categorical_feature=cat_cols, free_raw_data=False)\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=256,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_data_in_leaf=64,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbose=-1,\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train','valid'],\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "va_pred_lgb = lgb_model.predict(X_va_lgb, num_iteration=lgb_model.best_iteration)\n",
    "print(\"LightGBM AUC:\", roc_auc_score(y_va, va_pred_lgb))\n",
    "print(\"LightGBM PR-AUC:\", average_precision_score(y_va, va_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e02470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Важности признаков\n",
    "imp = pd.DataFrame({\n",
    "    'feature': lgb_model.feature_name(),\n",
    "    'importance': lgb_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False).head(40)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.barh(imp['feature'].iloc[::-1], imp['importance'].iloc[::-1])\n",
    "plt.title('LightGBM Feature Importance (gain, top-40)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a627258",
   "metadata": {},
   "source": [
    "## 10. XGBoost (OOF Target Encoding для категориальных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OOF Target Encoding для cat_cols\n",
    "def oof_target_encode(X, y, X_valid, X_test, cols, n_splits=5, smoothing=20, random_state=RANDOM_STATE, add_noise=0.0):\n",
    "    X = X.copy()\n",
    "    X_valid = X_valid.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    oof = pd.DataFrame(index=X.index)\n",
    "    te_models = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for c in cols:\n",
    "        oof[c] = np.nan\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        X_tr_f, X_va_f = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr_f = y.iloc[tr_idx]\n",
    "\n",
    "        te = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "        te.fit(X_tr_f, y_tr_f)\n",
    "        oof.iloc[va_idx] = te.transform(X_va_f)[cols].values\n",
    "        te_models.append(te)\n",
    "\n",
    "    # финальный энкодер на полном трейне для теста/валидации\n",
    "    te_full = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "    te_full.fit(X, y)\n",
    "    X_valid_te = te_full.transform(X_valid)[cols]\n",
    "    X_test_te  = te_full.transform(X_test)[cols]\n",
    "\n",
    "    # шум для регуляризации\n",
    "    if add_noise > 0:\n",
    "        noise = np.random.normal(0, add_noise, size=oof[cols].shape)\n",
    "        oof[cols] = oof[cols] + noise\n",
    "\n",
    "    # добавим TE фичи в датасеты\n",
    "    X_te_tr = X.copy()\n",
    "    X_te_va = X_valid.copy()\n",
    "    X_te_te = X_test.copy()\n",
    "    for c in cols:\n",
    "        X_te_tr[c + \"_te\"] = oof[c].astype(np.float32)\n",
    "        X_te_va[c + \"_te\"] = X_valid_te[c].astype(np.float32)\n",
    "        X_te_te[c + \"_te\"] = X_test_te[c].astype(np.float32)\n",
    "\n",
    "    # можно удалить исходные категориальные колонки, чтобы оставить только TE-варианты\n",
    "    X_te_tr = X_te_tr.drop(columns=cols)\n",
    "    X_te_va = X_te_va.drop(columns=cols)\n",
    "    X_te_te = X_te_te.drop(columns=cols)\n",
    "\n",
    "    return X_te_tr, X_te_va, X_te_te\n",
    "\n",
    "X_tr_xgb, X_va_xgb, X_te_xgb = oof_target_encode(X_tr, y_tr, X_va, X_te, cat_cols, n_splits=5, smoothing=20, add_noise=0.01)\n",
    "\n",
    "dtr = xgb.DMatrix(X_tr_xgb, label=y_tr)\n",
    "dva = xgb.DMatrix(X_va_xgb, label=y_va)\n",
    "dte = xgb.DMatrix(X_te_xgb)\n",
    "\n",
    "xgb_params = dict(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    min_child_weight=1.0,\n",
    "    tree_method='hist',\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtr,\n",
    "    num_boost_round=20000,\n",
    "    evals=[(dtr,'train'), (dva,'valid')],\n",
    "    early_stopping_rounds=300,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "va_pred_xgb = xgb_model.predict(dva, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "print(\"XGBoost AUC:\", roc_auc_score(y_va, va_pred_xgb))\n",
    "print(\"XGBoost PR-AUC:\", average_precision_score(y_va, va_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae20c8",
   "metadata": {},
   "source": [
    "## 11. CatBoost (нативные категории, Ordered Target Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CatBoost требует индексы категориальных фичей относительно X_* столбцов\n",
    "cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "train_pool = Pool(data=X_tr, label=y_tr, cat_features=cat_idx)\n",
    "valid_pool = Pool(data=X_va, label=y_va, cat_features=cat_idx)\n",
    "test_pool  = Pool(data=X_te, cat_features=cat_idx)\n",
    "\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=20000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    od_type='Iter',\n",
    "    od_wait=300,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "cb_model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "va_pred_cb = cb_model.predict_proba(valid_pool)[:,1]\n",
    "print(\"CatBoost AUC:\", roc_auc_score(y_va, va_pred_cb))\n",
    "print(\"CatBoost PR-AUC:\", average_precision_score(y_va, va_pred_cb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2741d",
   "metadata": {},
   "source": [
    "## 12. Сравнение и блендинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23275b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "scores = {\n",
    "    'LightGBM': roc_auc_score(y_va, va_pred_lgb),\n",
    "    'XGBoost':  roc_auc_score(y_va, va_pred_xgb),\n",
    "    'CatBoost': roc_auc_score(y_va, va_pred_cb),\n",
    "}\n",
    "print(\"AUC scores:\", scores)\n",
    "\n",
    "# Простой бленд (усреднение)\n",
    "va_blend = (va_pred_lgb + va_pred_xgb + va_pred_cb) / 3.0\n",
    "print(\"Blend AUC:\", roc_auc_score(y_va, va_blend))\n",
    "print(\"Blend PR-AUC:\", average_precision_score(y_va, va_blend))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78beab",
   "metadata": {},
   "source": [
    "## 13. Обучение на всём трейне и сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Для корректности можно пересобрать модели на всей тренировочной части (или на полном train).\n",
    "# Ниже — пример инференса на test с текущими моделями и усреднения предсказаний.\n",
    "\n",
    "# LightGBM\n",
    "te_pred_lgb = lgb_model.predict(X_te_lgb, num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "# XGBoost\n",
    "te_pred_xgb = xgb_model.predict(dte, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "\n",
    "# CatBoost\n",
    "te_pred_cb = cb_model.predict_proba(test_pool)[:,1]\n",
    "\n",
    "# Blend\n",
    "te_blend = (te_pred_lgb + te_pred_xgb + te_pred_cb) / 3.0\n",
    "\n",
    "sub = pd.read_csv(sub_path)\n",
    "sub['isFraud'] = te_blend\n",
    "out_path = \"./ieee_blend_submission.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71576582",
   "metadata": {},
   "source": [
    "\n",
    "## 14. Советы по улучшению\n",
    "- Более аккуратный **time-based CV** (rolling/expanding window).\n",
    "- Более богатый **feature engineering** (emaildomain группировки, браузеры/ОС, расстояния D*, взаимодействия C/V/*, device info).\n",
    "- **Hyperopt/Optuna** для подбора гиперпараметров.\n",
    "- Раздельные модели по «сценам» (например, по наличию identity-фичей).\n",
    "- Построение **SHAP**/Permutation importance для интерпретации.\n",
    "- Учет **class weights** (дисбаланс) и **focal loss** (в CatBoost/XGB).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
