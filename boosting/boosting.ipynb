{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b36f339-1839-485b-8412-15106340bf6a",
   "metadata": {},
   "source": [
    "ml 02.11\n",
    "\n",
    " ⁃ bias variance \n",
    "\n",
    "сложный датасет с нелин данными и большим обьемом\n",
    "\n",
    "анал данных: \n",
    " 1. пропуски, \n",
    " 2. константные признаки, \n",
    " 3. корреляция\n",
    " 4. zero split method (для всех признаков строим любой максимально глубокий бустинг с подбором параметров (много деревьев глубоких); после выводим feature importance и удаляем с нулевым.\n",
    " 5. для каждой пары скоррелированных признаков выводим корреляцию с таргетом и удаляем тот, у которого меньше.\n",
    " 6. все три вида бустинга lightGBM, XGBoost, CatBoost (из оф. библиотек). Для каждого используем любой удобный подбор параметров на валидации(70+15+15). Тестим на данных.\n",
    " 7. Проверка всех метрик: acc, rec, pr, roc auc, поиграться с cut off (построить кривую pr|rec и поток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c07902-bfc4-4481-8db9-dede076c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b4a2b0-759f-4f7a-aff7-6f9d0ca72c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download -c ieee-fraud-detection\n",
    "#!python -m venv sklearn-env\n",
    "#!sklearn-env\\Scripts\\activate с\n",
    "#!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7550375-f308-4183-a8af-8c84a2da871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, math, json, re, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346ffebb-00c1-417c-b833-67fa21045747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6927d3cc-f506-4f44-b781-be442156566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.model_selection  import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9358d2b6-d75d-4ea3-95b4-6e8f7017aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03c65e0-0cea-48f8-abed-e5e23edf43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac57af97-6cf2-4c61-b11f-ec9248b54daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2c9e2f-06bb-498c-8222-8650ef553ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05852213-42fe-463b-97c1-1cc0739fc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c6be27a-5585-4de4-889f-856dd13058b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa9470b-6eb8-4e05-9eff-e2c22a576c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"ieee-fraud-detection\"\n",
    "\n",
    "train_tr_path = os.path.join(DATA_DIR, \"train_transaction.csv\")\n",
    "train_id_path = os.path.join(DATA_DIR, \"train_identity.csv\")\n",
    "test_tr_path = os.path.join(DATA_DIR, \"test_transaction.csv\")\n",
    "test_id_path = os.path.join(DATA_DIR, \"test_identity.csv\")\n",
    "sub_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12ecc69f-0cc5-4bb4-ada3-ffa03ca08ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \n",
    "    # считаем, сколько памяти юзаем (deep=True учитывает размер самих значений,\n",
    "    # а не только контейнеров)\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type.kind in ['i','u','f']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if col_type.kind in ['i','u']:\n",
    "                if c_min >= 0:\n",
    "                    if c_max < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_max < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_max < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if np.iinfo(np.int8).min < c_min < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif np.iinfo(np.int16).min < c_min < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif np.iinfo(np.int32).min < c_min < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'object':\n",
    "            # не переводим автоматически в category, тк хз точно ли категориальные признаки\n",
    "            pass\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Mem. {start_mem:.2f} MB → {end_mem:.2f} MB\")\n",
    "    return df\n",
    "\n",
    "def read_csv_safely(path):\n",
    "    # Вариант с dtype=None, чтобы дать Pandas самому определить, затем downcast\n",
    "    df = pd.read_csv(path)\n",
    "    return reduce_mem_usage(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28d8aa45-e251-4d19-976d-d5769d206096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_id_columns(df):\n",
    "    df = df.rename(columns=lambda c: re.sub(r'^id-(\\d+)$', r'id_\\1', c))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ecd2cc8-8012-4744-bc81-b07c2494b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (590540, 434) test: (506691, 433) sub (506691, 2)\n"
     ]
    }
   ],
   "source": [
    "train_tr = pd.read_csv(train_tr_path)\n",
    "train_id = pd.read_csv(train_id_path)\n",
    "test_tr  = pd.read_csv(test_tr_path)\n",
    "test_id  = pd.read_csv(test_id_path)\n",
    "sub = pd.read_csv(sub_path)\n",
    "\n",
    "train = fix_id_columns(train_tr.merge(train_id, how='left', on='TransactionID'))\n",
    "test  = fix_id_columns(test_tr.merge(test_id,  how='left', on='TransactionID'))\n",
    "\n",
    "print(\"train:\", train.shape, \"test:\", test.shape, \"sub\", sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69cc4d23-a0b7-4e44-a98f-99d1257be489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03499000914417313\n",
      "id_24    0.991962\n",
      "id_25    0.991310\n",
      "id_07    0.991271\n",
      "id_08    0.991271\n",
      "id_21    0.991264\n",
      "id_26    0.991257\n",
      "id_22    0.991247\n",
      "id_27    0.991247\n",
      "id_23    0.991247\n",
      "dist2    0.936284\n",
      "dtype: float64\n",
      "tot_cols:  434\n",
      "num_cols:  403\n",
      "obj_cols:  31\n"
     ]
    }
   ],
   "source": [
    "target_col = 'isFraud'\n",
    "print(train[target_col].mean())\n",
    "miss = train.isna().mean().sort_values(ascending=False).head(10)\n",
    "miss.to_frame('miss_ratio')\n",
    "\n",
    "print(miss)\n",
    "\n",
    "print('tot_cols: ', train.shape[1])\n",
    "print('num_cols: ', train.select_dtypes(include=[np.number]).shape[1])\n",
    "print('obj_cols: ', train.select_dtypes(include=['object']).shape[1])\n",
    "\n",
    "cat_candidates = [c for c in train.columns if train[c].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fc5c99a-3b96-4c18-b490-95a55a865d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionDT — секунды с начала «нулевого» времени. Сделаем фичи:\n",
    "def add_time_features(df):\n",
    "    if 'TransactionDT' in df.columns:\n",
    "        df['DT'] = df['TransactionDT']\n",
    "        df['DT_day'] = (df['DT'] // (24*60*60)).astype('int32')\n",
    "        df['DT_hour'] = ((df['DT'] // (60*60)) % 24).astype('int16')\n",
    "        df['DT_dayofweek'] = (df['DT_day'] % 7).astype('int8')\n",
    "    return df\n",
    "\n",
    "def add_amount_features(df):\n",
    "    if 'TransactionAmt' in df.columns:\n",
    "        df['TransactionAmt_log1p'] = np.log1p(df['TransactionAmt'].astype(float))\n",
    "    return df\n",
    "\n",
    "def freq_encode(train, test, cols):\n",
    "    for c in cols:\n",
    "        fq = train[c].value_counts(dropna=False)\n",
    "        train[c + '_fq'] = train[c].map(fq)\n",
    "        test[c + '_fq']  = test[c].map(fq)\n",
    "    return train, test\n",
    "\n",
    "train = add_time_features(train)\n",
    "test  = add_time_features(test)\n",
    "train = add_amount_features(train)\n",
    "test  = add_amount_features(test)\n",
    "\n",
    "# Примеры частотных энкодингов для card1/addr1/emaildomain при наличии\n",
    "# freq_cols = [c for c in ['card1','addr1','P_emaildomain','R_emaildomain'] if c in train.columns]\n",
    "# train, test = freq_encode(train, test, freq_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd804cb-016d-4fb8-80fc-f0fd5efc5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [target_col, 'TransactionID']\n",
    "\n",
    "features = [c for c in train.columns if c not in drop_cols]\n",
    "\n",
    "# Временной сплит по TransactionDT: последний хвост как валидация\n",
    "cutoff = np.quantile(train['TransactionDT'], 0.85)  \n",
    "trn_idx = train['TransactionDT'] < cutoff\n",
    "val_idx = ~trn_idx\n",
    "\n",
    "X_tr = train.loc[trn_idx, features].reset_index(drop=True)\n",
    "y_tr = train.loc[trn_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "X_va = train.loc[val_idx, features].reset_index(drop=True)\n",
    "y_va = train.loc[val_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "\n",
    "X_te = test.loc[:,features].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec42168e-7526-42e2-be94-b800c2c25315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>...</th>\n",
       "      <th>id_22</th>\n",
       "      <th>id_24</th>\n",
       "      <th>id_25</th>\n",
       "      <th>id_26</th>\n",
       "      <th>id_32</th>\n",
       "      <th>DT</th>\n",
       "      <th>DT_day</th>\n",
       "      <th>DT_hour</th>\n",
       "      <th>DT_dayofweek</th>\n",
       "      <th>TransactionAmt_log1p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.019590e+05</td>\n",
       "      <td>501959.000000</td>\n",
       "      <td>501959.000000</td>\n",
       "      <td>494639.000000</td>\n",
       "      <td>501136.000000</td>\n",
       "      <td>498706.000000</td>\n",
       "      <td>445541.000000</td>\n",
       "      <td>445541.000000</td>\n",
       "      <td>198630.000000</td>\n",
       "      <td>33283.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4524.000000</td>\n",
       "      <td>4153.000000</td>\n",
       "      <td>4495.000000</td>\n",
       "      <td>4518.000000</td>\n",
       "      <td>68562.000000</td>\n",
       "      <td>5.019590e+05</td>\n",
       "      <td>501959.000000</td>\n",
       "      <td>501959.000000</td>\n",
       "      <td>501959.000000</td>\n",
       "      <td>501959.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.126156e+06</td>\n",
       "      <td>134.652819</td>\n",
       "      <td>9873.604133</td>\n",
       "      <td>362.801326</td>\n",
       "      <td>153.259281</td>\n",
       "      <td>199.572179</td>\n",
       "      <td>290.604427</td>\n",
       "      <td>86.780525</td>\n",
       "      <td>119.980345</td>\n",
       "      <td>236.128083</td>\n",
       "      <td>...</td>\n",
       "      <td>16.020778</td>\n",
       "      <td>12.773417</td>\n",
       "      <td>329.757508</td>\n",
       "      <td>148.590527</td>\n",
       "      <td>26.572387</td>\n",
       "      <td>6.126156e+06</td>\n",
       "      <td>70.307692</td>\n",
       "      <td>13.823922</td>\n",
       "      <td>2.944398</td>\n",
       "      <td>4.383301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.824121e+06</td>\n",
       "      <td>237.845691</td>\n",
       "      <td>4901.362169</td>\n",
       "      <td>157.956761</td>\n",
       "      <td>11.418906</td>\n",
       "      <td>40.938366</td>\n",
       "      <td>101.891595</td>\n",
       "      <td>2.819424</td>\n",
       "      <td>372.595205</td>\n",
       "      <td>538.790910</td>\n",
       "      <td>...</td>\n",
       "      <td>6.933404</td>\n",
       "      <td>2.244228</td>\n",
       "      <td>99.068855</td>\n",
       "      <td>32.371031</td>\n",
       "      <td>3.762732</td>\n",
       "      <td>3.824121e+06</td>\n",
       "      <td>44.260131</td>\n",
       "      <td>7.658789</td>\n",
       "      <td>2.018744</td>\n",
       "      <td>0.935103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.487993e+06</td>\n",
       "      <td>42.977500</td>\n",
       "      <td>6019.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.487993e+06</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.783678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.973411e+06</td>\n",
       "      <td>68.911000</td>\n",
       "      <td>9633.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.973411e+06</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.247223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.409264e+06</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>14135.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>9.409264e+06</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.836282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.315184e+07</td>\n",
       "      <td>31937.391000</td>\n",
       "      <td>18396.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>10286.000000</td>\n",
       "      <td>11623.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.315184e+07</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.371564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 406 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionDT  TransactionAmt          card1          card2  \\\n",
       "count   5.019590e+05   501959.000000  501959.000000  494639.000000   \n",
       "mean    6.126156e+06      134.652819    9873.604133     362.801326   \n",
       "std     3.824121e+06      237.845691    4901.362169     157.956761   \n",
       "min     8.640000e+04        0.251000    1000.000000     100.000000   \n",
       "25%     2.487993e+06       42.977500    6019.000000     214.000000   \n",
       "50%     5.973411e+06       68.911000    9633.000000     361.000000   \n",
       "75%     9.409264e+06      125.000000   14135.000000     512.000000   \n",
       "max     1.315184e+07    31937.391000   18396.000000     600.000000   \n",
       "\n",
       "               card3          card5          addr1          addr2  \\\n",
       "count  501136.000000  498706.000000  445541.000000  445541.000000   \n",
       "mean      153.259281     199.572179     290.604427      86.780525   \n",
       "std        11.418906      40.938366     101.891595       2.819424   \n",
       "min       100.000000     100.000000     100.000000      10.000000   \n",
       "25%       150.000000     166.000000     204.000000      87.000000   \n",
       "50%       150.000000     226.000000     299.000000      87.000000   \n",
       "75%       150.000000     226.000000     330.000000      87.000000   \n",
       "max       231.000000     237.000000     540.000000     102.000000   \n",
       "\n",
       "               dist1         dist2  ...        id_22        id_24  \\\n",
       "count  198630.000000  33283.000000  ...  4524.000000  4153.000000   \n",
       "mean      119.980345    236.128083  ...    16.020778    12.773417   \n",
       "std       372.595205    538.790910  ...     6.933404     2.244228   \n",
       "min         0.000000      0.000000  ...    10.000000    11.000000   \n",
       "25%         3.000000      7.000000  ...    14.000000    11.000000   \n",
       "50%         8.000000     37.000000  ...    14.000000    11.000000   \n",
       "75%        25.000000    218.000000  ...    14.000000    15.000000   \n",
       "max     10286.000000  11623.000000  ...    44.000000    26.000000   \n",
       "\n",
       "             id_25        id_26         id_32            DT         DT_day  \\\n",
       "count  4495.000000  4518.000000  68562.000000  5.019590e+05  501959.000000   \n",
       "mean    329.757508   148.590527     26.572387  6.126156e+06      70.307692   \n",
       "std      99.068855    32.371031      3.762732  3.824121e+06      44.260131   \n",
       "min     100.000000   100.000000      0.000000  8.640000e+04       1.000000   \n",
       "25%     321.000000   119.000000     24.000000  2.487993e+06      28.000000   \n",
       "50%     321.000000   147.000000     24.000000  5.973411e+06      69.000000   \n",
       "75%     371.000000   169.000000     32.000000  9.409264e+06     108.000000   \n",
       "max     548.000000   216.000000     32.000000  1.315184e+07     152.000000   \n",
       "\n",
       "             DT_hour   DT_dayofweek  TransactionAmt_log1p  \n",
       "count  501959.000000  501959.000000         501959.000000  \n",
       "mean       13.823922       2.944398              4.383301  \n",
       "std         7.658789       2.018744              0.935103  \n",
       "min         0.000000       0.000000              0.223943  \n",
       "25%         6.000000       1.000000              3.783678  \n",
       "50%        16.000000       3.000000              4.247223  \n",
       "75%        20.000000       5.000000              4.836282  \n",
       "max        23.000000       6.000000             10.371564  \n",
       "\n",
       "[8 rows x 406 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf4842e-810f-4993-987c-a44a5799df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in features if train[c].dtype == 'object']\n",
    "num_cols = [c for c in features if c not in cat_cols]\n",
    "\n",
    "# print(\"num_cols:\", len(num_cols), \"cat_cols:\", len(cat_cols))\n",
    "# cat_cols[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a4ff1-498a-4ccf-8f44-86e4de7d0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим object к category\n",
    "def cast_category(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "X_tr_lgb = X_tr.copy()\n",
    "X_va_lgb = X_va.copy()\n",
    "X_te_lgb = X_te.copy()\n",
    "\n",
    "X_tr_lgb = cast_category(X_tr_lgb, cat_cols)\n",
    "X_va_lgb = cast_category(X_va_lgb, cat_cols)\n",
    "X_te_lgb = cast_category(X_te_lgb, cat_cols)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr_lgb, label=y_tr, categorical_feature=cat_cols, free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(X_va_lgb, label=y_va, categorical_feature=cat_cols, free_raw_data=False)\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=256,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_data_in_leaf=64,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbose=-1,\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train','valid'],\n",
    ")\n",
    "\n",
    "va_pred_lgb = lgb_model.predict(X_va_lgb, num_iteration=lgb_model.best_iteration)\n",
    "print(\"LightGBM AUC:\", roc_auc_score(y_va, va_pred_lgb))\n",
    "print(\"LightGBM PR-AUC:\", average_precision_score(y_va, va_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc57a64-3db1-4b65-987d-6706d308e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Важности признаков\n",
    "imp = pd.DataFrame({\n",
    "    'feature': lgb_model.feature_name(),\n",
    "    'importance': lgb_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False).head(40)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.barh(imp['feature'].iloc[::-1], imp['importance'].iloc[::-1])\n",
    "plt.title('LightGBM Feature Importance (gain, top-40)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85d0dd-e558-4d1f-9f79-b5c781fa4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OOF Target Encoding для cat_cols\n",
    "def oof_target_encode(X, y, X_valid, X_test, cols, n_splits=5, smoothing=20, random_state=RANDOM_STATE, add_noise=0.0):\n",
    "    X = X.copy()\n",
    "    X_valid = X_valid.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    oof = pd.DataFrame(index=X.index)\n",
    "    te_models = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for c in cols:\n",
    "        oof[c] = np.nan\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        X_tr_f, X_va_f = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr_f = y.iloc[tr_idx]\n",
    "\n",
    "        te = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "        te.fit(X_tr_f, y_tr_f)\n",
    "        oof.iloc[va_idx] = te.transform(X_va_f)[cols].values\n",
    "        te_models.append(te)\n",
    "\n",
    "    # финальный энкодер на полном трейне для теста/валидации\n",
    "    te_full = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "    te_full.fit(X, y)\n",
    "    X_valid_te = te_full.transform(X_valid)[cols]\n",
    "    X_test_te  = te_full.transform(X_test)[cols]\n",
    "\n",
    "    # шум для регуляризации\n",
    "    if add_noise > 0:\n",
    "        noise = np.random.normal(0, add_noise, size=oof[cols].shape)\n",
    "        oof[cols] = oof[cols] + noise\n",
    "\n",
    "    # добавим TE фичи в датасеты\n",
    "    X_te_tr = X.copy()\n",
    "    X_te_va = X_valid.copy()\n",
    "    X_te_te = X_test.copy()\n",
    "    for c in cols:\n",
    "        X_te_tr[c + \"_te\"] = oof[c].astype(np.float32)\n",
    "        X_te_va[c + \"_te\"] = X_valid_te[c].astype(np.float32)\n",
    "        X_te_te[c + \"_te\"] = X_test_te[c].astype(np.float32)\n",
    "\n",
    "    # можно удалить исходные категориальные колонки, чтобы оставить только TE-варианты\n",
    "    X_te_tr = X_te_tr.drop(columns=cols)\n",
    "    X_te_va = X_te_va.drop(columns=cols)\n",
    "    X_te_te = X_te_te.drop(columns=cols)\n",
    "\n",
    "    return X_te_tr, X_te_va, X_te_te\n",
    "\n",
    "X_tr_xgb, X_va_xgb, X_te_xgb = oof_target_encode(X_tr, y_tr, X_va, X_te, cat_cols, n_splits=5, smoothing=20, add_noise=0.01)\n",
    "\n",
    "dtr = xgb.DMatrix(X_tr_xgb, label=y_tr)\n",
    "dva = xgb.DMatrix(X_va_xgb, label=y_va)\n",
    "dte = xgb.DMatrix(X_te_xgb)\n",
    "\n",
    "xgb_params = dict(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    min_child_weight=1.0,\n",
    "    tree_method='hist',\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtr,\n",
    "    num_boost_round=20000,\n",
    "    evals=[(dtr,'train'), (dva,'valid')],\n",
    "    early_stopping_rounds=300,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "va_pred_xgb = xgb_model.predict(dva, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "print(\"XGBoost AUC:\", roc_auc_score(y_va, va_pred_xgb))\n",
    "print(\"XGBoost PR-AUC:\", average_precision_score(y_va, va_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a95c4-5b3a-4063-88d6-c6dd6c93ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CatBoost требует индексы категориальных фичей относительно X_* столбцов\n",
    "cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "train_pool = Pool(data=X_tr, label=y_tr, cat_features=cat_idx)\n",
    "valid_pool = Pool(data=X_va, label=y_va, cat_features=cat_idx)\n",
    "test_pool  = Pool(data=X_te, cat_features=cat_idx)\n",
    "\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=20000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    od_type='Iter',\n",
    "    od_wait=300,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "cb_model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "va_pred_cb = cb_model.predict_proba(valid_pool)[:,1]\n",
    "print(\"CatBoost AUC:\", roc_auc_score(y_va, va_pred_cb))\n",
    "print(\"CatBoost PR-AUC:\", average_precision_score(y_va, va_pred_cb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707b834-f49e-4a96-a443-697a2df0beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "scores = {\n",
    "    'LightGBM': roc_auc_score(y_va, va_pred_lgb),\n",
    "    'XGBoost':  roc_auc_score(y_va, va_pred_xgb),\n",
    "    'CatBoost': roc_auc_score(y_va, va_pred_cb),\n",
    "}\n",
    "print(\"AUC scores:\", scores)\n",
    "\n",
    "# Простой бленд (усреднение)\n",
    "va_blend = (va_pred_lgb + va_pred_xgb + va_pred_cb) / 3.0\n",
    "print(\"Blend AUC:\", roc_auc_score(y_va, va_blend))\n",
    "print(\"Blend PR-AUC:\", average_precision_score(y_va, va_blend))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec30bf6-7615-4322-b6b7-51bf133c973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Для корректности можно пересобрать модели на всей тренировочной части (или на полном train).\n",
    "# Ниже — пример инференса на test с текущими моделями и усреднения предсказаний.\n",
    "\n",
    "# LightGBM\n",
    "te_pred_lgb = lgb_model.predict(X_te_lgb, num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "# XGBoost\n",
    "te_pred_xgb = xgb_model.predict(dte, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "\n",
    "# CatBoost\n",
    "te_pred_cb = cb_model.predict_proba(test_pool)[:,1]\n",
    "\n",
    "# Blend\n",
    "te_blend = (te_pred_lgb + te_pred_xgb + te_pred_cb) / 3.0\n",
    "\n",
    "sub = pd.read_csv(sub_path)\n",
    "sub['isFraud'] = te_blend\n",
    "out_path = \"./ieee_blend_submission.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
