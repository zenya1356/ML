{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b36f339-1839-485b-8412-15106340bf6a",
   "metadata": {},
   "source": [
    "ml 02.11\n",
    "\n",
    " ⁃ bias variance \n",
    "\n",
    "сложный датасет с нелин данными и большим обьемом\n",
    "\n",
    "анал данных: \n",
    " 1. пропуски, \n",
    " 2. константные признаки, \n",
    " 3. корреляция\n",
    " 4. zero split method (для всех признаков строим любой максимально глубокий бустинг с подбором параметров (много деревьев глубоких); после выводим feature importance и удаляем с нулевым.\n",
    " 5. для каждой пары скоррелированных признаков выводим корреляцию с таргетом и удаляем тот, у которого меньше.\n",
    " 6. все три вида бустинга lightGBM, XGBoost, CatBoost (из оф. библиотек). Для каждого используем любой удобный подбор параметров на валидации(70+15+15). Тестим на данных.\n",
    " 7. Проверка всех метрик: acc, rec, pr, roc auc, поиграться с cut off (построить кривую pr|rec и поток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33c07902-bfc4-4481-8db9-dede076c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72b4a2b0-759f-4f7a-aff7-6f9d0ca72c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download -c ieee-fraud-detection\n",
    "#!python -m venv sklearn-env\n",
    "#!sklearn-env\\Scripts\\activate с\n",
    "#!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7550375-f308-4183-a8af-8c84a2da871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, math, json, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "346ffebb-00c1-417c-b833-67fa21045747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6927d3cc-f506-4f44-b781-be442156566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.model_selection  import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9358d2b6-d75d-4ea3-95b4-6e8f7017aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d03c65e0-0cea-48f8-abed-e5e23edf43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac57af97-6cf2-4c61-b11f-ec9248b54daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d2c9e2f-06bb-498c-8222-8650ef553ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05852213-42fe-463b-97c1-1cc0739fc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c6be27a-5585-4de4-889f-856dd13058b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fa9470b-6eb8-4e05-9eff-e2c22a576c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"ieee-fraud-detection\"\n",
    "\n",
    "train_tr_path = os.path.join(DATA_DIR, \"train_transaction.csv\")\n",
    "train_id_path = os.path.join(DATA_DIR, \"train_identity.csv\")\n",
    "test_tr_path = os.path.join(DATA_DIR, \"test_transaction.csv\")\n",
    "test_id_path = os.path.join(DATA_DIR, \"test_identity.csv\")\n",
    "sub_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12ecc69f-0cc5-4bb4-ada3-ffa03ca08ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \n",
    "    # считаем, сколько памяти юзаем (deep=True учитывает размер самих значений,\n",
    "    # а не только контейнеров)\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type.kind in ['i','u','f']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if col_type.kind in ['i','u']:\n",
    "                if c_min >= 0:\n",
    "                    if c_max < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_max < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_max < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if np.iinfo(np.int8).min < c_min < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif np.iinfo(np.int16).min < c_min < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif np.iinfo(np.int32).min < c_min < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'object':\n",
    "            # не переводим автоматически в category, тк хз точно ли категориальные признаки\n",
    "            pass\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Mem. {start_mem:.2f} MB → {end_mem:.2f} MB\")\n",
    "    return df\n",
    "\n",
    "def read_csv_safely(path):\n",
    "    # Вариант с dtype=None, чтобы дать Pandas самому определить, затем downcast\n",
    "    df = pd.read_csv(path)\n",
    "    return reduce_mem_usage(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ecd2cc8-8012-4744-bc81-b07c2494b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. 2062.07 MB → 1203.22 MB\n",
      "Mem. 143.14 MB → 129.94 MB\n",
      "Mem. 1771.84 MB → 1038.31 MB\n",
      "Mem. 140.08 MB → 127.09 MB\n",
      "train: (590540, 434) test: (506691, 433)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "\n",
       "   card2  card3       card4  card5  ... id_31  id_32  id_33  id_34  id_35  \\\n",
       "0    NaN  150.0    discover  142.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
       "2  490.0  150.0        visa  166.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "  id_36 id_37  id_38  DeviceType  DeviceInfo  \n",
       "0   NaN   NaN    NaN         NaN         NaN  \n",
       "1   NaN   NaN    NaN         NaN         NaN  \n",
       "2   NaN   NaN    NaN         NaN         NaN  \n",
       "\n",
       "[3 rows x 434 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tr = read_csv_safely(train_tr_path)\n",
    "train_id = read_csv_safely(train_id_path)\n",
    "test_tr  = read_csv_safely(test_tr_path)\n",
    "test_id  = read_csv_safely(test_id_path)\n",
    "\n",
    "train = train_tr.merge(train_id, how='left', on='TransactionID')\n",
    "test  = test_tr.merge(test_id,  how='left', on='TransactionID')\n",
    "\n",
    "print(\"train:\", train.shape, \"test:\", test.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4270596-9d73-4c31-9b4a-122946a09242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>id_17</th>\n",
       "      <th>id_18</th>\n",
       "      <th>id_19</th>\n",
       "      <th>id_20</th>\n",
       "      <th>id_21</th>\n",
       "      <th>id_22</th>\n",
       "      <th>id_24</th>\n",
       "      <th>id_25</th>\n",
       "      <th>id_26</th>\n",
       "      <th>id_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>581607.000000</td>\n",
       "      <td>588975.000000</td>\n",
       "      <td>586281.000000</td>\n",
       "      <td>524834.000000</td>\n",
       "      <td>524834.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>139369.000000</td>\n",
       "      <td>45113.000000</td>\n",
       "      <td>139318.000000</td>\n",
       "      <td>139261.000000</td>\n",
       "      <td>5159.000000</td>\n",
       "      <td>5169.000000</td>\n",
       "      <td>4747.000000</td>\n",
       "      <td>5132.000000</td>\n",
       "      <td>5163.000000</td>\n",
       "      <td>77586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.034990</td>\n",
       "      <td>7.372311e+06</td>\n",
       "      <td>135.027161</td>\n",
       "      <td>9898.734658</td>\n",
       "      <td>362.555511</td>\n",
       "      <td>153.194946</td>\n",
       "      <td>199.278900</td>\n",
       "      <td>290.733826</td>\n",
       "      <td>86.800652</td>\n",
       "      <td>...</td>\n",
       "      <td>189.451370</td>\n",
       "      <td>14.237337</td>\n",
       "      <td>353.128174</td>\n",
       "      <td>403.882568</td>\n",
       "      <td>368.269806</td>\n",
       "      <td>16.002708</td>\n",
       "      <td>12.800927</td>\n",
       "      <td>329.608917</td>\n",
       "      <td>149.070312</td>\n",
       "      <td>26.508596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.704744e+05</td>\n",
       "      <td>0.183755</td>\n",
       "      <td>4.617224e+06</td>\n",
       "      <td>239.162689</td>\n",
       "      <td>4901.170153</td>\n",
       "      <td>157.817963</td>\n",
       "      <td>11.343591</td>\n",
       "      <td>41.332325</td>\n",
       "      <td>101.700386</td>\n",
       "      <td>2.773530</td>\n",
       "      <td>...</td>\n",
       "      <td>30.377136</td>\n",
       "      <td>1.561116</td>\n",
       "      <td>141.112030</td>\n",
       "      <td>152.158493</td>\n",
       "      <td>198.849014</td>\n",
       "      <td>6.897755</td>\n",
       "      <td>2.372468</td>\n",
       "      <td>97.462585</td>\n",
       "      <td>32.101933</td>\n",
       "      <td>3.737366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.987000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.134635e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.027058e+06</td>\n",
       "      <td>43.320999</td>\n",
       "      <td>6019.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.306528e+06</td>\n",
       "      <td>68.769001</td>\n",
       "      <td>9678.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.429904e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.124662e+07</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>14184.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>486.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.577539e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.581113e+07</td>\n",
       "      <td>31937.390625</td>\n",
       "      <td>18396.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>854.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionID        isFraud  TransactionDT  TransactionAmt  \\\n",
       "count   5.905400e+05  590540.000000   5.905400e+05   590540.000000   \n",
       "mean    3.282270e+06       0.034990   7.372311e+06      135.027161   \n",
       "std     1.704744e+05       0.183755   4.617224e+06      239.162689   \n",
       "min     2.987000e+06       0.000000   8.640000e+04        0.251000   \n",
       "25%     3.134635e+06       0.000000   3.027058e+06       43.320999   \n",
       "50%     3.282270e+06       0.000000   7.306528e+06       68.769001   \n",
       "75%     3.429904e+06       0.000000   1.124662e+07      125.000000   \n",
       "max     3.577539e+06       1.000000   1.581113e+07    31937.390625   \n",
       "\n",
       "               card1          card2          card3          card5  \\\n",
       "count  590540.000000  581607.000000  588975.000000  586281.000000   \n",
       "mean     9898.734658     362.555511     153.194946     199.278900   \n",
       "std      4901.170153     157.817963      11.343591      41.332325   \n",
       "min      1000.000000     100.000000     100.000000     100.000000   \n",
       "25%      6019.000000     214.000000     150.000000     166.000000   \n",
       "50%      9678.000000     361.000000     150.000000     226.000000   \n",
       "75%     14184.000000     512.000000     150.000000     226.000000   \n",
       "max     18396.000000     600.000000     231.000000     237.000000   \n",
       "\n",
       "               addr1          addr2  ...          id_17         id_18  \\\n",
       "count  524834.000000  524834.000000  ...  139369.000000  45113.000000   \n",
       "mean      290.733826      86.800652  ...     189.451370     14.237337   \n",
       "std       101.700386       2.773530  ...      30.377136      1.561116   \n",
       "min       100.000000      10.000000  ...     100.000000     10.000000   \n",
       "25%       204.000000      87.000000  ...     166.000000     13.000000   \n",
       "50%       299.000000      87.000000  ...     166.000000     15.000000   \n",
       "75%       330.000000      87.000000  ...     225.000000     15.000000   \n",
       "max       540.000000     102.000000  ...     229.000000     29.000000   \n",
       "\n",
       "               id_19          id_20        id_21        id_22        id_24  \\\n",
       "count  139318.000000  139261.000000  5159.000000  5169.000000  4747.000000   \n",
       "mean      353.128174     403.882568   368.269806    16.002708    12.800927   \n",
       "std       141.112030     152.158493   198.849014     6.897755     2.372468   \n",
       "min       100.000000     100.000000   100.000000    10.000000    11.000000   \n",
       "25%       266.000000     256.000000   252.000000    14.000000    11.000000   \n",
       "50%       341.000000     472.000000   252.000000    14.000000    11.000000   \n",
       "75%       427.000000     533.000000   486.500000    14.000000    15.000000   \n",
       "max       671.000000     661.000000   854.000000    44.000000    26.000000   \n",
       "\n",
       "             id_25        id_26         id_32  \n",
       "count  5132.000000  5163.000000  77586.000000  \n",
       "mean    329.608917   149.070312     26.508596  \n",
       "std      97.462585    32.101933      3.737366  \n",
       "min     100.000000   100.000000      0.000000  \n",
       "25%     321.000000   119.000000     24.000000  \n",
       "50%     321.000000   149.000000     24.000000  \n",
       "75%     371.000000   169.000000     32.000000  \n",
       "max     548.000000   216.000000     32.000000  \n",
       "\n",
       "[8 rows x 403 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a1ef9a1-6cbc-45c6-88ca-12d0539c10b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-32768, max=32767, dtype=int16)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69cc4d23-a0b7-4e44-a98f-99d1257be489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03499000914417313\n",
      "tot_cols:  434\n",
      "num_cols:  403\n",
      "obj_cols:  31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ProductCD',\n",
       " 'card4',\n",
       " 'card6',\n",
       " 'P_emaildomain',\n",
       " 'R_emaildomain',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'id_12',\n",
       " 'id_15',\n",
       " 'id_16',\n",
       " 'id_23',\n",
       " 'id_27',\n",
       " 'id_28',\n",
       " 'id_29',\n",
       " 'id_30',\n",
       " 'id_31',\n",
       " 'id_33',\n",
       " 'id_34',\n",
       " 'id_35',\n",
       " 'id_36',\n",
       " 'id_37',\n",
       " 'id_38',\n",
       " 'DeviceType',\n",
       " 'DeviceInfo']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = 'isFraud'\n",
    "print(train[target_col].mean())\n",
    "miss = train.isna().mean().sort_values(ascending=False).head(10)\n",
    "miss.to_frame('miss_ratio')\n",
    "\n",
    "print('tot_cols: ', train.shape[1])\n",
    "print('num_cols: ', train.select_dtypes(include=[np.number]).shape[1])\n",
    "print('obj_cols: ', train.select_dtypes(include=['object']).shape[1])\n",
    "\n",
    "cat_candidates = [c for c in train.columns if train[c].dtype == 'object']\n",
    "cat_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fc5c99a-3b96-4c18-b490-95a55a865d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TransactionDT — секунды с начала «нулевого» времени. Сделаем фичи:\n",
    "def add_time_features(df):\n",
    "    if 'TransactionDT' in df.columns:\n",
    "        df['DT'] = df['TransactionDT']\n",
    "        df['DT_day'] = (df['DT'] // (24*60*60)).astype('int32')\n",
    "        df['DT_hour'] = ((df['DT'] // (60*60)) % 24).astype('int16')\n",
    "        df['DT_dayofweek'] = (df['DT_day'] % 7).astype('int8')\n",
    "    return df\n",
    "\n",
    "def add_amount_features(df):\n",
    "    if 'TransactionAmt' in df.columns:\n",
    "        df['TransactionAmt_log1p'] = np.log1p(df['TransactionAmt'].astype(float))\n",
    "    return df\n",
    "\n",
    "def freq_encode(train, test, cols):\n",
    "    for c in cols:\n",
    "        fq = train[c].value_counts(dropna=False)\n",
    "        train[c + '_fq'] = train[c].map(fq)\n",
    "        test[c + '_fq']  = test[c].map(fq)\n",
    "    return train, test\n",
    "\n",
    "train = add_time_features(train)\n",
    "test  = add_time_features(test)\n",
    "train = add_amount_features(train)\n",
    "test  = add_amount_features(test)\n",
    "\n",
    "# Примеры частотных энкодингов для card1/addr1/emaildomain при наличии\n",
    "freq_cols = [c for c in ['card1','addr1','P_emaildomain','R_emaildomain'] if c in train.columns]\n",
    "train, test = freq_encode(train, test, freq_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4bd804cb-016d-4fb8-80fc-f0fd5efc5a04",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m X_va \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mloc[val_idx, features]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m y_va \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mloc[val_idx, target_col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m X_te \u001b[38;5;241m=\u001b[39m test[features]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_tr\u001b[38;5;241m.\u001b[39mshape, X_va\u001b[38;5;241m.\u001b[39mshape, X_te\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "drop_cols = [target_col, 'TransactionID']\n",
    "\n",
    "features = [c for c in train.columns if c not in drop_cols]\n",
    "\n",
    "# Временной сплит по TransactionDT: последний хвост как валидация\n",
    "cutoff = np.quantile(train['TransactionDT'], 0.85)  \n",
    "trn_idx = train['TransactionDT'] < cutoff\n",
    "val_idx = ~trn_idx\n",
    "\n",
    "X_tr = train.loc[trn_idx, features].reset_index(drop=True)\n",
    "y_tr = train.loc[trn_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "X_va = train.loc[val_idx, features].reset_index(drop=True)\n",
    "y_va = train.loc[val_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "\n",
    "X_te = test[features].reset_index(drop=True)\n",
    "\n",
    "print(X_tr.shape, X_va.shape, X_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4842e-810f-4993-987c-a44a5799df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Эвристика: object → категориальные\n",
    "cat_cols = [c for c in features if train[c].dtype == 'object']\n",
    "num_cols = [c for c in features if c not in cat_cols]\n",
    "\n",
    "print(\"num_cols:\", len(num_cols), \"cat_cols:\", len(cat_cols))\n",
    "cat_cols[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a4ff1-498a-4ccf-8f44-86e4de7d0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Приводим object к category\n",
    "def cast_category(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "X_tr_lgb = X_tr.copy()\n",
    "X_va_lgb = X_va.copy()\n",
    "X_te_lgb = X_te.copy()\n",
    "\n",
    "X_tr_lgb = cast_category(X_tr_lgb, cat_cols)\n",
    "X_va_lgb = cast_category(X_va_lgb, cat_cols)\n",
    "X_te_lgb = cast_category(X_te_lgb, cat_cols)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr_lgb, label=y_tr, categorical_feature=cat_cols, free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(X_va_lgb, label=y_va, categorical_feature=cat_cols, free_raw_data=False)\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=256,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_data_in_leaf=64,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbose=-1,\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train','valid'],\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "va_pred_lgb = lgb_model.predict(X_va_lgb, num_iteration=lgb_model.best_iteration)\n",
    "print(\"LightGBM AUC:\", roc_auc_score(y_va, va_pred_lgb))\n",
    "print(\"LightGBM PR-AUC:\", average_precision_score(y_va, va_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc57a64-3db1-4b65-987d-6706d308e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Важности признаков\n",
    "imp = pd.DataFrame({\n",
    "    'feature': lgb_model.feature_name(),\n",
    "    'importance': lgb_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False).head(40)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.barh(imp['feature'].iloc[::-1], imp['importance'].iloc[::-1])\n",
    "plt.title('LightGBM Feature Importance (gain, top-40)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85d0dd-e558-4d1f-9f79-b5c781fa4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OOF Target Encoding для cat_cols\n",
    "def oof_target_encode(X, y, X_valid, X_test, cols, n_splits=5, smoothing=20, random_state=RANDOM_STATE, add_noise=0.0):\n",
    "    X = X.copy()\n",
    "    X_valid = X_valid.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    oof = pd.DataFrame(index=X.index)\n",
    "    te_models = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for c in cols:\n",
    "        oof[c] = np.nan\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        X_tr_f, X_va_f = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr_f = y.iloc[tr_idx]\n",
    "\n",
    "        te = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "        te.fit(X_tr_f, y_tr_f)\n",
    "        oof.iloc[va_idx] = te.transform(X_va_f)[cols].values\n",
    "        te_models.append(te)\n",
    "\n",
    "    # финальный энкодер на полном трейне для теста/валидации\n",
    "    te_full = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "    te_full.fit(X, y)\n",
    "    X_valid_te = te_full.transform(X_valid)[cols]\n",
    "    X_test_te  = te_full.transform(X_test)[cols]\n",
    "\n",
    "    # шум для регуляризации\n",
    "    if add_noise > 0:\n",
    "        noise = np.random.normal(0, add_noise, size=oof[cols].shape)\n",
    "        oof[cols] = oof[cols] + noise\n",
    "\n",
    "    # добавим TE фичи в датасеты\n",
    "    X_te_tr = X.copy()\n",
    "    X_te_va = X_valid.copy()\n",
    "    X_te_te = X_test.copy()\n",
    "    for c in cols:\n",
    "        X_te_tr[c + \"_te\"] = oof[c].astype(np.float32)\n",
    "        X_te_va[c + \"_te\"] = X_valid_te[c].astype(np.float32)\n",
    "        X_te_te[c + \"_te\"] = X_test_te[c].astype(np.float32)\n",
    "\n",
    "    # можно удалить исходные категориальные колонки, чтобы оставить только TE-варианты\n",
    "    X_te_tr = X_te_tr.drop(columns=cols)\n",
    "    X_te_va = X_te_va.drop(columns=cols)\n",
    "    X_te_te = X_te_te.drop(columns=cols)\n",
    "\n",
    "    return X_te_tr, X_te_va, X_te_te\n",
    "\n",
    "X_tr_xgb, X_va_xgb, X_te_xgb = oof_target_encode(X_tr, y_tr, X_va, X_te, cat_cols, n_splits=5, smoothing=20, add_noise=0.01)\n",
    "\n",
    "dtr = xgb.DMatrix(X_tr_xgb, label=y_tr)\n",
    "dva = xgb.DMatrix(X_va_xgb, label=y_va)\n",
    "dte = xgb.DMatrix(X_te_xgb)\n",
    "\n",
    "xgb_params = dict(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    min_child_weight=1.0,\n",
    "    tree_method='hist',\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtr,\n",
    "    num_boost_round=20000,\n",
    "    evals=[(dtr,'train'), (dva,'valid')],\n",
    "    early_stopping_rounds=300,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "va_pred_xgb = xgb_model.predict(dva, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "print(\"XGBoost AUC:\", roc_auc_score(y_va, va_pred_xgb))\n",
    "print(\"XGBoost PR-AUC:\", average_precision_score(y_va, va_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a95c4-5b3a-4063-88d6-c6dd6c93ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CatBoost требует индексы категориальных фичей относительно X_* столбцов\n",
    "cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "train_pool = Pool(data=X_tr, label=y_tr, cat_features=cat_idx)\n",
    "valid_pool = Pool(data=X_va, label=y_va, cat_features=cat_idx)\n",
    "test_pool  = Pool(data=X_te, cat_features=cat_idx)\n",
    "\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=20000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    od_type='Iter',\n",
    "    od_wait=300,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "cb_model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "va_pred_cb = cb_model.predict_proba(valid_pool)[:,1]\n",
    "print(\"CatBoost AUC:\", roc_auc_score(y_va, va_pred_cb))\n",
    "print(\"CatBoost PR-AUC:\", average_precision_score(y_va, va_pred_cb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707b834-f49e-4a96-a443-697a2df0beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "scores = {\n",
    "    'LightGBM': roc_auc_score(y_va, va_pred_lgb),\n",
    "    'XGBoost':  roc_auc_score(y_va, va_pred_xgb),\n",
    "    'CatBoost': roc_auc_score(y_va, va_pred_cb),\n",
    "}\n",
    "print(\"AUC scores:\", scores)\n",
    "\n",
    "# Простой бленд (усреднение)\n",
    "va_blend = (va_pred_lgb + va_pred_xgb + va_pred_cb) / 3.0\n",
    "print(\"Blend AUC:\", roc_auc_score(y_va, va_blend))\n",
    "print(\"Blend PR-AUC:\", average_precision_score(y_va, va_blend))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec30bf6-7615-4322-b6b7-51bf133c973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Для корректности можно пересобрать модели на всей тренировочной части (или на полном train).\n",
    "# Ниже — пример инференса на test с текущими моделями и усреднения предсказаний.\n",
    "\n",
    "# LightGBM\n",
    "te_pred_lgb = lgb_model.predict(X_te_lgb, num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "# XGBoost\n",
    "te_pred_xgb = xgb_model.predict(dte, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "\n",
    "# CatBoost\n",
    "te_pred_cb = cb_model.predict_proba(test_pool)[:,1]\n",
    "\n",
    "# Blend\n",
    "te_blend = (te_pred_lgb + te_pred_xgb + te_pred_cb) / 3.0\n",
    "\n",
    "sub = pd.read_csv(sub_path)\n",
    "sub['isFraud'] = te_blend\n",
    "out_path = \"./ieee_blend_submission.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
