{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7bae09-7c71-4b49-b0e0-a15260b6da53",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36f339-1839-485b-8412-15106340bf6a",
   "metadata": {},
   "source": [
    "ml 02.11\n",
    "\n",
    " ⁃ bias variance \n",
    "\n",
    "сложный датасет с нелин данными и большим обьемом\n",
    "\n",
    "анал данных: \n",
    " 1. пропуски, \n",
    " 2. константные признаки, \n",
    " 3. корреляция\n",
    " 4. zero split method (для всех признаков строим любой максимально глубокий бустинг с подбором параметров (много деревьев глубоких); после выводим feature importance и удаляем с нулевым.\n",
    " 5. для каждой пары скоррелированных признаков выводим корреляцию с таргетом и удаляем тот, у которого меньше.\n",
    " 6. все три вида бустинга lightGBM, XGBoost, CatBoost (из оф. библиотек). Для каждого используем любой удобный подбор параметров на валидации(70+15+15). Тестим на данных.\n",
    " 7. Проверка всех метрик: acc, rec, pr, roc auc, поиграться с cut off (построить кривую pr|rec и поток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33c07902-bfc4-4481-8db9-dede076c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72b4a2b0-759f-4f7a-aff7-6f9d0ca72c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download -c ieee-fraud-detection\n",
    "#!python -m venv sklearn-env\n",
    "#!sklearn-env\\Scripts\\activate с\n",
    "#!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7550375-f308-4183-a8af-8c84a2da871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, math, json, re, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "346ffebb-00c1-417c-b833-67fa21045747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6927d3cc-f506-4f44-b781-be442156566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.model_selection  import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9358d2b6-d75d-4ea3-95b4-6e8f7017aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d03c65e0-0cea-48f8-abed-e5e23edf43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac57af97-6cf2-4c61-b11f-ec9248b54daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d2c9e2f-06bb-498c-8222-8650ef553ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "05852213-42fe-463b-97c1-1cc0739fc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8c6be27a-5585-4de4-889f-856dd13058b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6fa9470b-6eb8-4e05-9eff-e2c22a576c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"ieee-fraud-detection\"\n",
    "\n",
    "train_tr_path = os.path.join(DATA_DIR, \"train_transaction.csv\")\n",
    "train_id_path = os.path.join(DATA_DIR, \"train_identity.csv\")\n",
    "test_tr_path = os.path.join(DATA_DIR, \"test_transaction.csv\")\n",
    "test_id_path = os.path.join(DATA_DIR, \"test_identity.csv\")\n",
    "sub_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12ecc69f-0cc5-4bb4-ada3-ffa03ca08ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \n",
    "    # считаем, сколько памяти юзаем (deep=True учитывает размер самих значений,\n",
    "    # а не только контейнеров)\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type.kind in ['i','u','f']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if col_type.kind in ['i','u']:\n",
    "                if c_min >= 0:\n",
    "                    if c_max < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif c_max < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif c_max < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if np.iinfo(np.int8).min < c_min < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif np.iinfo(np.int16).min < c_min < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif np.iinfo(np.int32).min < c_min < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'object':\n",
    "            # не переводим автоматически в category, тк хз точно ли категориальные признаки\n",
    "            pass\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Mem. {start_mem:.2f} MB → {end_mem:.2f} MB\")\n",
    "    return df\n",
    "\n",
    "def read_csv_safely(path):\n",
    "    # Вариант с dtype=None, чтобы дать Pandas самому определить, затем downcast\n",
    "    df = pd.read_csv(path)\n",
    "    return reduce_mem_usage(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "28d8aa45-e251-4d19-976d-d5769d206096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_id_columns(df):\n",
    "    df = df.rename(columns=lambda c: re.sub(r'^id-(\\d+)$', r'id_\\1', c))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7ecd2cc8-8012-4744-bc81-b07c2494b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (590540, 434) test: (506691, 433) sub (506691, 2)\n"
     ]
    }
   ],
   "source": [
    "train_tr = pd.read_csv(train_tr_path)\n",
    "train_id = pd.read_csv(train_id_path)\n",
    "test_tr  = pd.read_csv(test_tr_path)\n",
    "test_id  = pd.read_csv(test_id_path)\n",
    "sub = pd.read_csv(sub_path)\n",
    "\n",
    "train = fix_id_columns(train_tr.merge(train_id, how='left', on='TransactionID'))\n",
    "test  = fix_id_columns(test_tr.merge(test_id,  how='left', on='TransactionID'))\n",
    "\n",
    "print(\"train:\", train.shape, \"test:\", test.shape, \"sub\", sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "69cc4d23-a0b7-4e44-a98f-99d1257be489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03499000914417313\n",
      "id_24    0.991962\n",
      "id_25    0.991310\n",
      "id_07    0.991271\n",
      "id_08    0.991271\n",
      "id_21    0.991264\n",
      "id_26    0.991257\n",
      "id_22    0.991247\n",
      "id_27    0.991247\n",
      "id_23    0.991247\n",
      "dist2    0.936284\n",
      "dtype: float64\n",
      "tot_cols:  434\n",
      "num_cols:  403\n",
      "obj_cols:  31\n"
     ]
    }
   ],
   "source": [
    "target_col = 'isFraud'\n",
    "print(train[target_col].mean())\n",
    "miss = train.isna().mean().sort_values(ascending=False).head(10)\n",
    "miss.to_frame('miss_ratio')\n",
    "\n",
    "print(miss)\n",
    "\n",
    "print('tot_cols: ', train.shape[1])\n",
    "print('num_cols: ', train.select_dtypes(include=[np.number]).shape[1])\n",
    "print('obj_cols: ', train.select_dtypes(include=['object']).shape[1])\n",
    "\n",
    "cat_candidates = [c for c in train.columns if train[c].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1fc5c99a-3b96-4c18-b490-95a55a865d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionDT — секунды с начала «нулевого» времени. Сделаем фичи:\n",
    "def add_time_features(df):\n",
    "    if 'TransactionDT' in df.columns:\n",
    "        df['DT'] = df['TransactionDT']\n",
    "        df['DT_day'] = (df['DT'] // (24*60*60)).astype('int32')\n",
    "        df['DT_hour'] = ((df['DT'] // (60*60)) % 24).astype('int16')\n",
    "        df['DT_dayofweek'] = (df['DT_day'] % 7).astype('int8')\n",
    "    return df\n",
    "\n",
    "def add_amount_features(df):\n",
    "    if 'TransactionAmt' in df.columns:\n",
    "        df['TransactionAmt_log1p'] = np.log1p(df['TransactionAmt'].astype(float))\n",
    "    return df\n",
    "\n",
    "def freq_encode(train, test, cols):\n",
    "    for c in cols:\n",
    "        fq = train[c].value_counts(dropna=False)\n",
    "        train[c + '_fq'] = train[c].map(fq)\n",
    "        test[c + '_fq']  = test[c].map(fq)\n",
    "    return train, test\n",
    "\n",
    "train = add_time_features(train)\n",
    "test  = add_time_features(test)\n",
    "train = add_amount_features(train)\n",
    "test  = add_amount_features(test)\n",
    "\n",
    "# Примеры частотных энкодингов для card1/addr1/emaildomain при наличии\n",
    "# freq_cols = [c for c in ['card1','addr1','P_emaildomain','R_emaildomain'] if c in train.columns]\n",
    "# train, test = freq_encode(train, test, freq_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4bd804cb-016d-4fb8-80fc-f0fd5efc5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [target_col, 'TransactionID']\n",
    "\n",
    "features = [c for c in train.columns if c not in drop_cols]\n",
    "\n",
    "# Временной сплит по TransactionDT: последний хвост как валидация\n",
    "cutoff = np.quantile(train['TransactionDT'], 0.85)  \n",
    "trn_idx = train['TransactionDT'] < cutoff\n",
    "val_idx = ~trn_idx\n",
    "\n",
    "X_tr = train.loc[trn_idx, features].reset_index(drop=True)\n",
    "y_tr = train.loc[trn_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "X_va = train.loc[val_idx, features].reset_index(drop=True)\n",
    "y_va = train.loc[val_idx, target_col].astype('int8').reset_index(drop=True)\n",
    "\n",
    "X_te = test.loc[:,features].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ccf4842e-810f-4993-987c-a44a5799df00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols: 401 cat_cols: 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ProductCD',\n",
       " 'card4',\n",
       " 'card6',\n",
       " 'P_emaildomain',\n",
       " 'R_emaildomain',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'M6',\n",
       " 'M7',\n",
       " 'M8',\n",
       " 'M9',\n",
       " 'id_12',\n",
       " 'id_15',\n",
       " 'id_16',\n",
       " 'id_23',\n",
       " 'id_27',\n",
       " 'id_28']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [c for c in features if train[c].dtype == 'object']\n",
    "num_cols = [c for c in features if c not in cat_cols]\n",
    "\n",
    "# print(\"num_cols:\", len(num_cols), \"cat_cols:\", len(cat_cols))\n",
    "# cat_cols[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "665a4ff1-498a-4ccf-8f44-86e4de7d0dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 33\u001b[0m\n\u001b[0;32m     16\u001b[0m lgb_valid \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_va_lgb, label\u001b[38;5;241m=\u001b[39my_va, categorical_feature\u001b[38;5;241m=\u001b[39mcat_cols, free_raw_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m lgb_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     19\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     seed\u001b[38;5;241m=\u001b[39mRANDOM_STATE,\n\u001b[0;32m     31\u001b[0m )\n\u001b[1;32m---> 33\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     34\u001b[0m     lgb_params,\n\u001b[0;32m     35\u001b[0m     lgb_train,\n\u001b[0;32m     36\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[0;32m     37\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[lgb_train, lgb_valid],\n\u001b[0;32m     38\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     39\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m     40\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     43\u001b[0m va_pred_lgb \u001b[38;5;241m=\u001b[39m lgb_model\u001b[38;5;241m.\u001b[39mpredict(X_va_lgb, num_iteration\u001b[38;5;241m=\u001b[39mlgb_model\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightGBM AUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, roc_auc_score(y_va, va_pred_lgb))\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# Приводим object к category\n",
    "def cast_category(df, cols):\n",
    "    for c in cols:\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "X_tr_lgb = X_tr.copy()\n",
    "X_va_lgb = X_va.copy()\n",
    "X_te_lgb = X_te.copy()\n",
    "\n",
    "X_tr_lgb = cast_category(X_tr_lgb, cat_cols)\n",
    "X_va_lgb = cast_category(X_va_lgb, cat_cols)\n",
    "X_te_lgb = cast_category(X_te_lgb, cat_cols)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr_lgb, label=y_tr, categorical_feature=cat_cols, free_raw_data=False)\n",
    "lgb_valid = lgb.Dataset(X_va_lgb, label=y_va, categorical_feature=cat_cols, free_raw_data=False)\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=256,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_data_in_leaf=64,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    verbose=-1,\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train','valid'],\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "va_pred_lgb = lgb_model.predict(X_va_lgb, num_iteration=lgb_model.best_iteration)\n",
    "print(\"LightGBM AUC:\", roc_auc_score(y_va, va_pred_lgb))\n",
    "print(\"LightGBM PR-AUC:\", average_precision_score(y_va, va_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc57a64-3db1-4b65-987d-6706d308e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Важности признаков\n",
    "imp = pd.DataFrame({\n",
    "    'feature': lgb_model.feature_name(),\n",
    "    'importance': lgb_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False).head(40)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.barh(imp['feature'].iloc[::-1], imp['importance'].iloc[::-1])\n",
    "plt.title('LightGBM Feature Importance (gain, top-40)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85d0dd-e558-4d1f-9f79-b5c781fa4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OOF Target Encoding для cat_cols\n",
    "def oof_target_encode(X, y, X_valid, X_test, cols, n_splits=5, smoothing=20, random_state=RANDOM_STATE, add_noise=0.0):\n",
    "    X = X.copy()\n",
    "    X_valid = X_valid.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    oof = pd.DataFrame(index=X.index)\n",
    "    te_models = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for c in cols:\n",
    "        oof[c] = np.nan\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        X_tr_f, X_va_f = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr_f = y.iloc[tr_idx]\n",
    "\n",
    "        te = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "        te.fit(X_tr_f, y_tr_f)\n",
    "        oof.iloc[va_idx] = te.transform(X_va_f)[cols].values\n",
    "        te_models.append(te)\n",
    "\n",
    "    # финальный энкодер на полном трейне для теста/валидации\n",
    "    te_full = ce.TargetEncoder(cols=cols, smoothing=smoothing)\n",
    "    te_full.fit(X, y)\n",
    "    X_valid_te = te_full.transform(X_valid)[cols]\n",
    "    X_test_te  = te_full.transform(X_test)[cols]\n",
    "\n",
    "    # шум для регуляризации\n",
    "    if add_noise > 0:\n",
    "        noise = np.random.normal(0, add_noise, size=oof[cols].shape)\n",
    "        oof[cols] = oof[cols] + noise\n",
    "\n",
    "    # добавим TE фичи в датасеты\n",
    "    X_te_tr = X.copy()\n",
    "    X_te_va = X_valid.copy()\n",
    "    X_te_te = X_test.copy()\n",
    "    for c in cols:\n",
    "        X_te_tr[c + \"_te\"] = oof[c].astype(np.float32)\n",
    "        X_te_va[c + \"_te\"] = X_valid_te[c].astype(np.float32)\n",
    "        X_te_te[c + \"_te\"] = X_test_te[c].astype(np.float32)\n",
    "\n",
    "    # можно удалить исходные категориальные колонки, чтобы оставить только TE-варианты\n",
    "    X_te_tr = X_te_tr.drop(columns=cols)\n",
    "    X_te_va = X_te_va.drop(columns=cols)\n",
    "    X_te_te = X_te_te.drop(columns=cols)\n",
    "\n",
    "    return X_te_tr, X_te_va, X_te_te\n",
    "\n",
    "X_tr_xgb, X_va_xgb, X_te_xgb = oof_target_encode(X_tr, y_tr, X_va, X_te, cat_cols, n_splits=5, smoothing=20, add_noise=0.01)\n",
    "\n",
    "dtr = xgb.DMatrix(X_tr_xgb, label=y_tr)\n",
    "dva = xgb.DMatrix(X_va_xgb, label=y_va)\n",
    "dte = xgb.DMatrix(X_te_xgb)\n",
    "\n",
    "xgb_params = dict(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    min_child_weight=1.0,\n",
    "    tree_method='hist',\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtr,\n",
    "    num_boost_round=20000,\n",
    "    evals=[(dtr,'train'), (dva,'valid')],\n",
    "    early_stopping_rounds=300,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "va_pred_xgb = xgb_model.predict(dva, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "print(\"XGBoost AUC:\", roc_auc_score(y_va, va_pred_xgb))\n",
    "print(\"XGBoost PR-AUC:\", average_precision_score(y_va, va_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a95c4-5b3a-4063-88d6-c6dd6c93ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CatBoost требует индексы категориальных фичей относительно X_* столбцов\n",
    "cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "train_pool = Pool(data=X_tr, label=y_tr, cat_features=cat_idx)\n",
    "valid_pool = Pool(data=X_va, label=y_va, cat_features=cat_idx)\n",
    "test_pool  = Pool(data=X_te, cat_features=cat_idx)\n",
    "\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=20000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    od_type='Iter',\n",
    "    od_wait=300,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "cb_model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "va_pred_cb = cb_model.predict_proba(valid_pool)[:,1]\n",
    "print(\"CatBoost AUC:\", roc_auc_score(y_va, va_pred_cb))\n",
    "print(\"CatBoost PR-AUC:\", average_precision_score(y_va, va_pred_cb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707b834-f49e-4a96-a443-697a2df0beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "scores = {\n",
    "    'LightGBM': roc_auc_score(y_va, va_pred_lgb),\n",
    "    'XGBoost':  roc_auc_score(y_va, va_pred_xgb),\n",
    "    'CatBoost': roc_auc_score(y_va, va_pred_cb),\n",
    "}\n",
    "print(\"AUC scores:\", scores)\n",
    "\n",
    "# Простой бленд (усреднение)\n",
    "va_blend = (va_pred_lgb + va_pred_xgb + va_pred_cb) / 3.0\n",
    "print(\"Blend AUC:\", roc_auc_score(y_va, va_blend))\n",
    "print(\"Blend PR-AUC:\", average_precision_score(y_va, va_blend))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec30bf6-7615-4322-b6b7-51bf133c973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Для корректности можно пересобрать модели на всей тренировочной части (или на полном train).\n",
    "# Ниже — пример инференса на test с текущими моделями и усреднения предсказаний.\n",
    "\n",
    "# LightGBM\n",
    "te_pred_lgb = lgb_model.predict(X_te_lgb, num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "# XGBoost\n",
    "te_pred_xgb = xgb_model.predict(dte, iteration_range=(0, xgb_model.best_ntree_limit))\n",
    "\n",
    "# CatBoost\n",
    "te_pred_cb = cb_model.predict_proba(test_pool)[:,1]\n",
    "\n",
    "# Blend\n",
    "te_blend = (te_pred_lgb + te_pred_xgb + te_pred_cb) / 3.0\n",
    "\n",
    "sub = pd.read_csv(sub_path)\n",
    "sub['isFraud'] = te_blend\n",
    "out_path = \"./ieee_blend_submission.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
